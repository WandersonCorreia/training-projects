"""
Aether Architect (Modo Multi-Backend)

Este script conecta a uma API compat√≠vel com OpenAIou a uma inst√¢ncia Ollama local
para gerar um site ao vivo.

--- CONFIGURA√á√ÉO ---
Instale a biblioteca necess√°ria para o seu backend escolhido:
- Para OpenAI: pip install openai
- Para Ollama: pip install ollama

--- USO ---
Voc√™ deve especificar um backend ('openai' ou 'ollama') e um modelo.

# Exemplo para OLLAMA:
python ai_server.py ollama --model llama3

# Exemplo para compat√≠vel com OpenAI(ex: LM Studio):
python ai_server.py openai --model "lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF"
"""
import http.server
import socketserver
import os
import argparse
import re
from urllib.parse import urlparse, parse_qs

# Importa bibliotecas condicionalmente
try:
    import openai
except ImportError:
    openai = None
try:
    import ollama
except ImportError:
    ollama = None

# --- 1. PROMPT DE SISTEMA DETALHADO E ULTRA-ESTRITO ---
SYSTEM_PROMPT_BRAND_CUSTODIAN = """
Voc√™ √© The Brand Custodian, um desenvolvedor front-end de IA especializado. Seu √∫nico prop√≥sito √© construir e manter o site oficial de uma empresa espec√≠fica e predefinida. Voc√™ deve garantir que cada peda√ßo de conte√∫do, cada escolha de design e cada intera√ß√£o que voc√™ cria esteja perfeitamente alinhado com a identidade e a hist√≥ria detalhadas da marca fornecidas abaixo. Seu objetivo √© consist√™ncia e representa√ß√£o fiel.

---
### 1. O CLIENTE: Terranexa (Marca e Hist√≥ria)
*   **Nome da Empresa:** **Terranexa**
*   **Fundadores:** Dr. Aris Thorne (bi√≥logo vision√°rio), Lena Petrova (engenheira de sistemas pragm√°tica).
*   **Fundada:** 2019
*   **Hist√≥ria de Origem:** Se conheceram em uma confer√™ncia de tecnologia clim√°tica, frustrados com solu√ß√µes que tratavam a natureza como um recurso. Esbo√ßaram o conceito "Symbiotic Grid" em um guardanapo.
*   **Miss√£o:** Criar ecossistemas autossustent√°veis, harmonizando tecnologia com a natureza.
*   **Vis√£o:** Um mundo onde ambientes urbanos e naturais prosperam em perfeita simbiose.
*   **Princ√≠pios Fundamentais:** 1. Design Simbi√≥tico, 2. Transpar√™ncia Radical (dados de c√≥digo aberto), 3. Resili√™ncia de Longo Prazo.
*   **Tecnologias Essenciais:** Sensores biodegrad√°veis, gerenciamento de recursos baseado em IA, agricultura vertical urbana, capta√ß√£o de umidade atmosf√©rica.

---
### 2. REGRAS ESTRUTURAIS OBRIGAT√ìRIAS
**A. Barra de Navega√ß√£o Fixa:**
*   Uma √∫nica barra de navega√ß√£o fixa na parte superior da janela de visualiza√ß√£o.
*   DEVE conter estes 5 links em ordem: Home, Nossa Tecnologia, Sustentabilidade, Sobre N√≥s, Contato. (Use links de consulta adequados: /?prompt=...).
**B. Ano de Copyright:**
*   Se existir um rodap√©, o ano de copyright DEVE ser **2025**.

---
### 3. DIRETIVAS T√âCNICAS E CRIATIVAS
**A. Mandato Estrito de Arquivo √önico (CR√çTICO):**
*   Sua resposta inteira **DEVE** ser um √∫nico arquivo HTML.
*   Voc√™ **N√ÉO DEVE** sob nenhuma circunst√¢ncia vincular a arquivos externos. Isso significa especificamente **SEM tags `<link rel="stylesheet" ...>` e SEM tags `<script src="..."></script>` .**
*   Todo CSS **DEVE** ser colocado dentro de uma √∫nica tag `<style>` dentro da tag `<head>`HTML.
*   Todo JavaScript **DEVE** ser colocado dentro de uma tag `<script>` , de prefer√™ncia antes da tag `</body>` de fechamento.

**B. Sem Sintaxe Markdown (Estritamente Aplicado):**
*   Voc√™ **N√ÉO DEVE** usar nenhuma sintaxe Markdown. Use tags HTML para toda a formata√ß√£o (`<em>`, `<strong>`, `<h1>`, `<ul>`, etc.).

**C. Design Visual:**
*   O estilo deve estar alinhado com a marca Terranexa: inovador, org√¢nico, limpo, confi√°vel.
"""

# Globais que ser√£o configurados por argumentos de linha de comando
CLIENTE = None
MODELO_NOME = None
AI_BACKEND = None

# --- MANIPULADOR DO SERVIDOR WEB ---


class AIWebsiteHandler(http.server.BaseHTTPRequestHandler):
    BLOCKED_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.gif',
                          '.svg', '.ico', '.css', '.js', '.woff', '.woff2', '.ttf')

    def do_GET(self):
        global CLIENTE, MODELO_NOME, AI_BACKEND
        try:
            parsed_url = urlparse(self.path)
            path_component = parsed_url.path.lower()

            if path_component.endswith(self.BLOCKED_EXTENSIONS):
                self.send_error(404, "Arquivo N√£o Encontrado")
                return

            if not CLIENTE:
                self.send_error(503, "Servi√ßo de IA N√£o Configurado")
                return

            query_components = parse_qs(parsed_url.query)
            user_prompt = query_components.get("prompt", [None])[0]

            if not user_prompt:
                user_prompt = "Gere a p√°gina inicial para a Terranexa. Ela deve ter uma se√ß√£o de her√≥i forte que apresente a vis√£o e a miss√£o da empresa com base em sua hist√≥ria principal."

            print(
                f"\nüöÄ Recebida solicita√ß√£o de p√°gina v√°lida para o backend '{AI_BACKEND}': {self.path}")
            print(
                f"üí¨ Enviando prompt para o modelo '{MODELO_NOME}': '{user_prompt}'")

            messages = [{"role": "system", "content": SYSTEM_PROMPT_BRAND_CUSTODIAN}, {
                "role": "user", "content": user_prompt}]

            raw_content = None
            # --- CHAMADA DE API DE BACKEND DUPLO ---
            if AI_BACKEND == 'openai':
                response = CLIENTE.chat.completions.create(
                    model=MODELO_NOME, messages=messages, temperature=0.7)
                raw_content = response.choices[0].message.content
            elif AI_BACKEND == 'ollama':
                response = CLIENTE.chat(model=MODELO_NOME, messages=messages)
                raw_content = response['message']['content']

            # --- LIMPEZA INTELIGENTE DE CONTE√öDO ---
            html_content = ""
            if isinstance(raw_content, str):
                html_content = raw_content
            elif isinstance(raw_content, dict) and 'String' in raw_content:
                html_content = raw_content['String']
            else:
                html_content = str(raw_content)

            html_content = re.sub(r'<think>.*?</think>',
                                  '', html_content, flags=re.DOTALL).strip()
            if html_content.startswith("```html"):
                html_content = html_content[7:-3].strip()
            elif html_content.startswith("```"):
                html_content = html_content[3:-3].strip()

            self.send_response(200)
            self.send_header("Content-type", "text/html; charset=utf-8")
            self.end_headers()
            self.wfile.write(html_content.encode("utf-8"))
            print("‚úÖ P√°gina gerada e servida com sucesso.")

        except BrokenPipeError:
            print(
                f"üî∂ [BrokenPipeError] Cliente desconectado para o caminho: {self.path}. Solicita√ß√£o abortada.")
        except Exception as e:
            print(f"‚ùå Ocorreu um erro inesperado: {e}")
            try:
                self.send_error(500, f"Erro do Servidor: {e}")
            except Exception as e2:
                print(
                    f"üî¥ Ocorreu um erro adicional ao lidar com o erro inicial: {e2}")


# --- BLOCO DE EXECU√á√ÉO PRINCIPAL ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Aether Architect: Servidor Web de IA Multi-Backend", formatter_class=argparse.RawTextHelpFormatter)

    # Escolha do backend
    parser.add_argument('backend', choices=[
                        'openai', 'ollama'], help='O backend de IA a ser usado.')

    # Argumentos comuns
    parser.add_argument("--model", type=str, required=True,
                        help="O identificador do modelo a ser usado (por exemplo, 'llama3').")
    parser.add_argument("--port", type=int, default=8000,
                        help="Porta para executar o servidor web.")

    # Argumentos espec√≠ficos do backend
    openai_group = parser.add_argument_group(
        'Op√ß√µes OpenAI (para o backend "openai")')
    openai_group.add_argument("--api-base", type=str, default="http://localhost:1234/v1",
                              help="URL base do servidor de API compat√≠vel com OpenAI.")
    openai_group.add_argument(
        "--api-key", type=str, default="not-needed", help="Chave de API para o servi√ßo.")

    ollama_group = parser.add_argument_group(
        'Op√ß√µes Ollama (para o backend "ollama")')
    ollama_group.add_argument("--ollama-host", type=str, default="http://127.0.0.1:11434",
                              help="Endere√ßo do host para o servidor Ollama.")

    args = parser.parse_args()

    PORT = args.port
    MODELO_NOME = args.model
    AI_BACKEND = args.backend

    # --- INICIALIZA√á√ÉO DO CLIENTE ---
    if AI_BACKEND == 'openai':
        if not openai:
            print("üî¥ Backend 'openai' escolhido, mas a biblioteca n√£o foi encontrada. Execute 'pip install openai'")
            exit(1)
        try:
            print(
                f"üîó Conectando ao servidor compat√≠vel com OpenAIem: {args.api_base}")
            CLIENTE = openai.OpenAI(
                base_url=args.api_base, api_key=args.api_key)
            print(
                f"‚úÖ Cliente OpenAI configurado para usar o modelo: '{MODELO_NOME}'")
        except Exception as e:
            print(f"üî¥ Falha ao configurar o cliente OpenAI : {e}")
            exit(1)

    elif AI_BACKEND == 'ollama':
        if not ollama:
            print("üî¥ Backend 'ollama' escolhido, mas a biblioteca n√£o foi encontrada. Execute 'pip install ollama'")
            exit(1)
        try:
            print(f"üîó Conectando ao servidor Ollama em: {args.ollama_host}")
            CLIENTE = ollama.Client(host=args.ollama_host)
            # Verifique a conex√£o listando os modelos locais
            CLIENTE.list()
            print(
                f"‚úÖ Cliente Ollama configurado para usar o modelo: '{MODELO_NOME}'")
        except Exception as e:
            print(f"üî¥ Falha ao conectar ao servidor Ollama. Ele est√° rodando?")
            print(f"   Erro: {e}")
            exit(1)

    socketserver.TCPServer.allow_reuse_address = True
    with socketserver.TCPServer(("", PORT), AIWebsiteHandler) as httpd:
        print(f"\n‚ú® The Brand Custodian est√° no ar em http://localhost:{PORT}")
        print(
            f"   (Usando o backend '{AI_BACKEND}' com o modelo '{MODELO_NOME}')")
        print("   (Pressione Ctrl+C para parar o servidor)")
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\n desligando o servidor.")
            httpd.shutdown()
